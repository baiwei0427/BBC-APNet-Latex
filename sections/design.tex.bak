\section{Solution}\label{sec:design}
\vspace{-2mm}
\subsection{Design Goals}\label{subsec:design_goals}
We seek to achieve both high throughput and low packet loss rate simultaneously. However, as shown in $\S\ref{sec:problem}$, the scarce buffer resource in high-speed switching chips makes it difficult to achieve both metrics when many ports are active simultaneously. When a conflict arises between the two metrics, we prefer to keep low packet loss rate at the cost of sacrificing a small amount of throughput. This is because the bandwidth is generally plentiful in datacenters, while a small increase in packet loss rate (\eg, $\geq0.1\%$) can seriously degrade the application performance and in turn, operator revenue~\cite{timely}. Furthermore, our solution should work with existing commodity switches and be backward compatible with legacy network stacks. Modifying switch hardware is especially problematic as a new switch ASIC typically takes years to design and implement.

\subsection{\sys Mechanism}\label{subsec:mechanism}
\begin{table}[t]
\small
\centering
\begin{tabular}{|C{1.5cm}|C{6cm}|}
\hline
Parameter & Description\\ \hline
$B$ &  Switch shared buffer size\\ \hline
$N$ &  Total number of switch egress queues \\ \hline
$C$ &  Capacity of the switch queue \\ \hline
$RTT$ & Base round-trip time \\ \hline
$\alpha$ & Parameter for shared buffer allocation\\ \hline
$B_{R}$ & Minimum per-queue required buffer for high throughput and low packet loss rate\\ \hline
$K_{min}$ & Minimum marking threshold for shared buffer ECN/RED\\ \hline
$K_{max}$ & Maximum marking threshold for shared buffer ECN/RED\\ \hline
$P_{max}$ & Maximum marking probability for shared buffer ECN/RED\\ \hline
$h$ & See Equation~\ref{eq:k_min}\\ \hline
\end{tabular}
\vspace{-2mm}
\caption{Shared buffer model parameters}\label{tab:parameter}
\vspace{-2mm}
\end{table}
\begin{table}[t]
\centering
\small
\begin{tabular}{|C{1.5cm}|C{6cm}|}
\hline
Variable & Description\\ \hline
$t$ & Time\\ \hline
$Q_{i}(t)$ & Length of switch queue $i$ at time $t$\\ \hline
$T(t)$ & Queue length control threshold at time $t$\\ \hline
\end{tabular}
\vspace{-2mm}
\caption{Shared buffer model variables}\label{tab:variable}
\vspace{-2mm}
\end{table}
We model the switch as a shared-buffer output-queued switch. Variables and parameters used in the model are listed in Table~\ref{tab:parameter} and~\ref{tab:variable}. We start from the simplest assumption that each switch port only contains a single egress queue\footnote{In $\S\ref{subsec:mechanism}$ and $\S\ref{subsec:parameter}$, we use queue and port interchangeably.} and no buffer is reserved for each queue. Hence, all buffers are dynamically allocated from a single shared buffer pool. The switch has $B$ (shared) buffer space and $N$ egress queues in total. An ECN-based transport~\cite{dctcp,tuning,d2tcp,l2dct,acdc,vcc} is enabled at the end host. The standard ECN setting has been configured on each port/queue to achieve 100\% throughput.

Today's commodity switching chip (especially those from Broadcom) typically use Dynamic Threshold (DT) algorithm~\cite{dt} for dynamic buffer allocation. The shared buffer allocated to a queue is controlled by a parameter $\alpha$. At time $t$, the MMU will compute a threshold $T(t)$ to limit the queue length. $T(t)$ is actually a function of the unused shared buffer size and $\alpha$ as follows:
\vspace{-1mm}
\begin{equation}
\vspace{-2mm}
T(t)=\alpha\times(B-\displaystyle\sum_{i=1}^{N} Q_{i}(t))\label{eq:dt}
\vspace{-1mm}
\end{equation}
A packet arriving in queue $i$ at time $t$ will get dropped if $Q_{i}(t)\geq T(t)$. As analyzed in~\cite{dt}, if there are $M$ active queues, each queue can eventually get $\alpha\times B/(1+M\times \alpha)$ buffer space. The more active queues we have, the smaller buffer space each queue can get from the shared pool. $\alpha$ values are typically powers of two for hardware implementation simplicity (\eg, 1/128 to 8 in Tomhawk).

We assume that our ECN-based transport protocol requires at least $B_R$ buffer space per queue to achieve both high throughput and low packet loss rate. We simply treat $B_R$ as a known constant here and show how to determine $B_R$ later in $\S\ref{subsec:parameter}$. When $T(t) > B_R$, it means that the switch has sufficient buffer space to achieve both goals simultaneously. Hence, \sys just marks packets like the standard ECN configuration without degrading throughput.

When $T(t) \leq B_R$, it indicates that the shared buffer pool is highly utilized by many concurrently active ports. In such scenarios, only relying on standard ECN configuration may cause excessive packet losses as analyzed in $\S\ref{subsec:buffer-aggressive}$. Hence, \sys throttles the shared buffer occupancy to avoid excessive packet losses. By Equation~\ref{eq:dt} and $T(t)\leq B_R$, we derive that
\vspace{-1mm}
\begin{equation}
\vspace{-2mm}
\displaystyle\sum_{i=1}^{N} Q_{i}(t)\geq B-B_{R}/\alpha\label{eq:shared_buffer}
\vspace{-2mm}
\end{equation}
Here $\displaystyle\sum_{i=1}^{N} Q_{i}(t)$ is the occupancy of the shared buffer pool at time $t$, and $B$, $B_{R}$ and $\alpha$ are all known parameters. This implies that, to prevent excessive packet losses, \sys should throttle the shared buffer occupancy from exceeding a static threshold $B-B_{R}/\alpha$.

To realize this, we leverage the shared buffer ECN/RED functionality which has been widely supported in commodity switching chips~\cite{arista_ecn,cisco_ecn,mqecn}. Shared buffer ECN/RED follows the original RED algorithm~\cite{RED} but tracks the occupancy of a shared buffer pool to mark packets. Note that all transmitted packets in the shared buffer pool can get marked regardless of their ingress/egress ports and queues. Therefore, shared buffer ECN/RED can effectively control shared buffer occupancies. Moreover, shared buffer ECN/RED can be used in combination with other ECN/AQM configurations at the switch. When there are several ECN configurations enabled, a packet gets marked if anyone decides to mark it first.

\vspace{-1mm}
\parab{Summary:}\sys is built on top of existing ECN-based transports and per-port standard ECN configuration (current practice). It further enables shared buffer ECN/RED at the switch to achieve buffer-aware congestion control.
\begin{icompact}
\item When few ports are active, the shared buffer resource is abundant and per-port standard ECN configuration will take effect first to strike the balance of high throughput and low latency as before~\cite{dctcp}. Both high throughput and low packet loss rate can be achieved.
\vspace{-1mm}
\item When more and more ports become congested, the shared buffer resource turns scarcer. Shared buffer ECN/RED will be automatically triggered first to prevent packet losses at the cost of sacrificing a small amount of bandwidth.
\vspace{-1mm}
\end{icompact}

\subsection{Parameter Selection}\label{subsec:parameter}
We now derive several parameters for \sys. First, we determine $B_R$, the minimum per-queue (port) buffer size for both high throughput and low packet loss rate. With $B_R$ fixed, we then decide marking thresholds and probability of shared ECN/RED. Note that in this section we give several useful rules-of-thumb to set parameters while leaving optimal parameter settings for future work.

\vspace{-1mm}
\parab{Determine $B_R$:}Statistics has shown that there is typically a small number of concurrent large flows to the same receiver in DCNs~\cite{dctcp}. Hence, we consider a simple scenario where several synchronized long-lived flows share a bottleneck link. $C\times RTT\times \lambda$ per port buffering is required for 100\% throughput.

However, the lag in ECN control loop imposes extra buffer requirement to avoid packet losses. When a packet gets ECN marked at switch egress\footnote{Modern shared buffer switches mark packets using RED at egress side~\cite{ecn_or_delay}.}, the sender will reduce its window after one $RTT$. During this $RTT$ interval, extra buffer space is required to absorb the queue increase. We consider the most challenging TCP slow start phase. As an ACK packet can trigger two MTU-sized data packets, the aggregate sending rate reaches $2C$ and the switch queue gradient is $C$. Therefore we need $C\times RTT$ extra buffer space to avoid packet losses and $C\times RTT\times (1+\lambda)$ buffer space in total to achieve both goals.

We also 
In summary, we recommend setting $B_R$ to $C\times RTT\times (1+\lambda)$. As $C$ and $\lambda$ are both known and $RTT$ can be measured~\cite{pingmesh,tuning} in production DCNs, operators can easily compute the value of $B_R$.

\vspace{-1mm}
\parab{Determine parameters for shared buffer ECN/RED:}We leverage shared buffer ECN/RED to prevent the shared buffer occupancy from exceeding $B-B_{R}/\alpha$. To achieve fast reaction to bursty traffic, we mark packets based on the instantaneous buffer occupancy. Shared buffer ECN/RED has 3 parameters to configure: minimum threshold $K_{min}$, maximum threshold $K_{max}$ and maximum probability $P_{max}$. When the buffer occupancy is: 1) below $K_{min}$, no packet is marked; 2) between $K_{min}$ and $K_{max}$, packets are marked according to a probability; 3) exceeds $K_{max}$, all packets get marked.

Inspired by  DCTCP~\cite{dctcp}, our first choice is to set $K_{min}=K_{max}\leq B-B_{R}/\alpha$, in which we only need to determine a single marking threshold. However, with such cut-off setting, we find all flows sharing a buffer pool are likely to reduce their window at the same time, resulting in global synchronization problem and a further loss of throughput~\cite{RED}.

Therefore, we decided to perform a probabilistic marking by setting $K_{min}<K_{max}=B-B_{R}/\alpha$.
%As analyzed before, when the buffer occupancy exceeds $K_{max}=B-B_{R}/\alpha$, packets are likely to get dropped. Hence, we should mark each packet to reduce the shared buffer occupancy immediately despite the loss of throughput due to synchronization problem.
%When the buffer occupancy is between $K_{min}$ and $K_{max}$, packets are marked according to a probability.
The key here is to control the range between $K_{min}$ and $K_{max}$. A too small $K_{max}-K_{min}$ will make buffer occupancy regularly ramp up beyond $K_{max}$, still causing global synchronization and even packet losses. As original RED work~\cite{RED} suggests, $K_{max}-K_{min}$ should be made sufficiently large (\eg, larger than typical increase in the shared buffer occupancy during a RTT) to avoid global synchronization. Hence, the choice of $K_{max}-K_{min}$ depends on both the number of ports $N$ and link capacity $C$. In \sys, we set $K_{min}$ as follows:
\begin{equation}
\vspace{-1mm}
\displaystyle K_{min}=B-B_{R}/\alpha-C\times N\times h\label{eq:k_min}
\vspace{-1mm}
\end{equation}
where $h$ is a parameter to control $K_{max}-K_{min}$. In our evaluation, we set $h$ to 8$\mu$s. For the maximum marking probability $P_{max}$, we set it to 10\% following the guideline in~\cite{RED}. 

\subsection{Discussion}\label{subsec:discussion}
In this section, we first discuss several factors that may affect the design of \sys. Then we discuss \sys's compatibility with delay-based transports.

\parab{Impact of multiple MMUs:}Some switching chips (\eg, Broadcom Tomahawk) have multiple MMUs and dynamic buffer allocation only happens within the single MMU. \sys also takes effect in such architecture as the shared buffer ECN/RED operates in a per-MMU manner. Each MMU has its own shared buffer ECN/RED and only marks its own packets based on its own shared buffer occupancy (see validation in $\S\ref{subsec:experiments}$).

\parab{Impact of different $\alpha$ values:}Each switch egress port has multiple (\eg, 4 to 8) queues for traffic isolation and scheduling. To provide differentiated network services, operators may configure different $\alpha$ values for different queues.

When there are different $\alpha$ values, we can choose the minimum value $\alpha_{min}$ among them and update shared buffer ECN/RED parameters as follows: $K_{max}=B-B_{R}/\alpha_{min}$, $K_{min}=B-B_{R}/\alpha_{min}-C\times N\times h$.

\parab{Impact of static reserved buffers:}In $\S\ref{subsec:mechanism}$, we simply assume that all buffers are dynamically allocated. In practice, each egress queue has a small amount of static reserved buffer by default. Operators can also configure different reserved buffer sizes for different queues based on their importances.

When both static reserved buffers and dynamic shared buffers exist, the MMU first tries to use static reserved buffers. Therefore, we should reduce $B_R$, the minimum per-queue shared buffer size for both high throughput and low packet loss rate, to incorporate the static reserved buffer into \sys. Let $S_{min}$ denote the minimum static buffer size reserved for a single queue. Our recommended value for $B_R$ should become $C\times RTT\times (1+\lambda)-S_{min}$




